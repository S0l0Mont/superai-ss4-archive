{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67158,"databundleVersionId":7460879,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup ","metadata":{"id":"RlBFJFY-N1v9"}},{"cell_type":"code","source":"!pip install -q open_clip_torch transformers","metadata":{"id":"gtspLp2yqQui"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir ~/.kaggle\n!cp /content/kaggle.json ~/.kaggle/ #copy api key ---- depend on your directory -- my directory is .../colab/..\n!chmod 600 ~/.kaggle/kaggle.json\n!kaggle competitions download -c image-search #download competition dataset","metadata":{"id":"lvBIqQDkcjVb","outputId":"a85db907-a38d-4b11-9fe6-8ba31661814e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /content/image-search.zip","metadata":{"id":"nRPNsrq6c55Y","outputId":"e91674d7-ea87-4e3c-c3a8-2c1f95ade152"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport open_clip\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch\n\nfrom numpy.linalg import norm\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\nfrom torchvision import transforms\nfrom sklearn.decomposition import PCA","metadata":{"id":"w0Jqck-2qsKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_FOLDER = '/content/test/images'\nQUERY_FOLDER = '/content/queries/queries'\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"id":"MhrtQBgfqT5u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PadToSquare(object):\n    def __init__(self):\n        return\n\n    def __call__(self, image):\n        width, height = image.size\n        l, t, r, b = 0, 0, 0, 0\n\n        if width < height:\n            lr = height - width\n            if lr % 2 == 0:\n                l, r = lr // 2, lr // 2\n            else:\n                l, r = lr // 2 + 1, lr // 2\n\n        elif height < width:\n            tb = width - height\n            if tb % 2 == 0:\n                t, b = tb // 2, tb // 2\n            else:\n                t, b = tb // 2 + 1, tb // 2\n\n        padding = transforms.Pad([l, t, r, b], padding_mode='edge')\n        return padding(image)","metadata":{"id":"IUMuhzpLcD_O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"open_clip.list_pretrained()","metadata":{"id":"Ew9PQu4zdU4W","outputId":"3444e6e6-93a3-4a8d-a122-d843a0efc482"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, _, org_transform = open_clip.create_model_and_transforms(\n  model_name=\"ViT-H-14-quickgelu\",\n  pretrained=\"metaclip_fullcc\",\n  device=device\n)\n\ntransform = transforms.Compose([\n    PadToSquare(),\n    org_transform\n])\n\ntransform_gray = transforms.Compose([\n    PadToSquare(),\n    transforms.Grayscale(3),\n    org_transform\n])","metadata":{"id":"GmpsfY_8qWaS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform","metadata":{"id":"IJt_bilA4Mj5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_gray","metadata":{"id":"069JqYltcD_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get train image embeddings","metadata":{"id":"pKNl7KBfOC41"}},{"cell_type":"code","source":"data_df = pd.read_csv('/content/sample_submission.csv')","metadata":{"id":"mqQUEHDu1QH5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_ls = []\n\nfor dirname, _, filenames in os.walk(QUERY_FOLDER):\n    for filename in filenames:\n        if filename.endswith('.jpg'):\n            query_ls.append([\n                filename,\n                dirname.split('/')[-1]\n            ])\nquery_df = pd.DataFrame(query_ls, columns=['filepath', 'class'])","metadata":{"id":"UrmmL4VsseEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df = data_df.rename(columns={'img_file': 'filepath'})\ndata_df = data_df.drop('class', axis=1)","metadata":{"id":"RiljhqK_cD_S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_df = query_df.drop('class', axis=1)","metadata":{"id":"PfGAsoYJcD_T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image.open(os.path.join(QUERY_FOLDER, query_df.iloc[1]['filepath'])).convert(\"RGB\")","metadata":{"id":"2dHEnlwGzfdb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LogoDataset(Dataset):\n    def __init__(self, df, transform, folder):\n        self.df = df\n        self.transform = transform\n        self.folder = folder\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        return self.transform(Image.open(os.path.join(self.folder, self.df.iloc[idx]['filepath'])).convert(\"RGB\"))","metadata":{"id":"2-LavuNSvR7k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_ds = LogoDataset(data_df, transform, TEST_FOLDER)\ndata_gray_ds = LogoDataset(data_df, transform_gray, TEST_FOLDER)\nquery_ds = LogoDataset(query_df, transform, QUERY_FOLDER)\n\ndata_loader = DataLoader(data_ds, batch_size=64)\ndata_gray_loader = DataLoader(data_gray_ds, batch_size=64)\nquery_loader = DataLoader(query_ds, batch_size=64)","metadata":{"id":"eZusWayly58q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_ds[1].shape","metadata":{"id":"3rA_7pBDzDRX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(query_ds[1].permute(1, 2, 0))","metadata":{"id":"PtBTSnmWcD_W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(data_ds[1006].permute(1, 2, 0))","metadata":{"id":"2t_x8nyVcD_W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embs = []\nrunning_vloss = 0\n\nwith torch.no_grad():\n    for inputs in tqdm(data_loader):\n        inputs = inputs.to(device)\n        outputs = model.encode_image(inputs)\n\n        embs.append(outputs.detach().cpu().numpy())\n\ndata_embs = np.concatenate(embs)\ndata_embs.shape","metadata":{"id":"r5nip_Rju_0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embs = []\nrunning_vloss = 0\n\nwith torch.no_grad():\n    for inputs in tqdm(data_gray_loader):\n        inputs = inputs.to(device)\n        outputs = model.encode_image(inputs)\n\n        embs.append(outputs.detach().cpu().numpy())\n\ndata_gray_embs = np.concatenate(embs)\ndata_gray_embs.shape","metadata":{"id":"AqgeuOyUcD_X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embs = []\nrunning_vloss = 0\n\nwith torch.no_grad():\n    for inputs in tqdm(query_loader):\n        inputs = inputs.to(device)\n        outputs = model.encode_image(inputs)\n\n        embs.append(outputs.detach().cpu().numpy())\n\nquery_embs = np.concatenate(embs)\nquery_embs.shape","metadata":{"id":"XJyU5I13--ok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df['emb'] = list(data_embs)\ndata_gray_df = data_df.copy()\ndata_gray_df['emb'] = list(data_gray_embs)\nquery_df['emb'] = list(query_embs)","metadata":{"id":"nN7zqura_VAb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df","metadata":{"id":"GQtdh4VpW-1o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gray_df","metadata":{"id":"tSkb4y36cD_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(query_embs, 'query.pt')\ntorch.save(data_embs, 'test.pt')\ntorch.save(data_gray_embs, 'test_gray.pt')","metadata":{"id":"nceZEtxDQiIc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate","metadata":{"id":"Dto4EeyxbRg7"}},{"cell_type":"code","source":"data_emb = np.stack(data_df['emb'])\ndata_gray_emb = np.stack(data_gray_df['emb'])\nquery_emb = np.stack(query_df['emb'])\nprint(data_emb.shape)\nprint(data_gray_emb.shape)\nprint(query_emb.shape)","metadata":{"id":"ZbuzUr1AcD_a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df = data_df[['filepath', 'emb']]\ndata_gray_df = data_gray_df[['filepath', 'emb']]","metadata":{"id":"WtwYJwEEmN_Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gray_df","metadata":{"id":"R0ozIysKm-IB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = euclidean_distances(query_emb, data_emb)\nresult_gray = euclidean_distances(query_emb, data_gray_emb)\nprint(result.shape)\nprint(result_gray.shape)","metadata":{"id":"2zfrAyOgQTIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_gray","metadata":{"id":"qA8HvpN0cD_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df","metadata":{"id":"URt-6vU5Jb6Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df['pred'] = '22.jpg'\ndata_df['min'] = 1000","metadata":{"id":"RS3LlVnnnygm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df","metadata":{"id":"5dhuQpmyoJvu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result","metadata":{"id":"a4lnqrUgIQdJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.min(result)","metadata":{"id":"muNUyS7acD_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.max(result)","metadata":{"id":"kc4Sc1ueCQYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.min(result_gray)","metadata":{"id":"a0fZwCMdNkQf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.max(result_gray)","metadata":{"id":"WALi6msJNl6I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Choosing threshold is different between each models","metadata":{"id":"7-Qzs9v5sWQc"}},{"cell_type":"code","source":"thres = 1.1\n\n\nfor i in tqdm(range(len(result))):\n    threshold = thres\n    pred = query_df.iloc[i]['filepath']\n    result_min = np.minimum(result, result_gray)\n    if pred == '3.jpg' or pred == '20.jpg':\n      threshold+=0.05\n    print(f\"filename: {pred}, threshold: {threshold}\")\n    new_min = np.where(result_min[i] < threshold, result_min[i], 1000)\n    m = data_df['min']\n    data_df['pred'] = data_df['pred'].where(new_min >= m, pred)\n    data_df['min'] = data_df['min'].where(new_min >= m, new_min)","metadata":{"id":"UZhra6HmRCEk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df.value_counts('pred')","metadata":{"id":"eRkiYwlJsZuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df","metadata":{"id":"0yEUAeYtcD_d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = data_df[['filepath', 'pred']].rename(columns={'filepath': 'img_file', 'pred': 'class'})\nsub_df['class'] = sub_df['class'].apply(lambda x: int(x.replace('.jpg', '')))","metadata":{"id":"s145s0FScD_d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df","metadata":{"id":"7N3OWTSgcD_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.value_counts(\"class\")","metadata":{"id":"Zsmf6qB6GkgT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('sub_ViT-H-14-CLIPA-336_datacomp1b_eu_pad_edge.csv', index=False)","metadata":{"id":"rBqn0-nVcD_g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble\n- ลืมชื่อโมเดลครับตั้งมั่วเกิน55","metadata":{"id":"268K6Ed2q23v"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n \n# Read in the prediction CSV files for each model\nmodel1_preds = pd.read_csv(\"Main.csv\")\nmodel2_preds = pd.read_csv(\n    \"Secondary.csv\")\nmodel3_preds = pd.read_csv(\"tertiary.csv\")\n\n# Merge the prediction CSV files into a single DataFrame\nmerged_preds = pd.merge(model1_preds, model2_preds, on=\"img_file\")\nmerged_preds = pd.merge(merged_preds, model3_preds, on=\"img_file\")\n\n\n# Define the function to perform majority voting\ndef majority_voting(row):\n    counts = np.bincount(row)\n    return np.argmax(counts)\n\n# Apply the majority voting function to the merged DataFrame\nmerged_preds[\"Ensemble_Prediction\"] = merged_preds.iloc[:, 1:].apply(majority_voting, axis=1)\nmerged_preds['class'] = merged_preds[\"Ensemble_Prediction\"]\nmerged_preds = merged_preds[['img_file','class']]\n# Save the final prediction CSV file\nmerged_preds.to_csv(\"ensemble_preds.csv\", index=False)","metadata":{"id":"KEbsiSSxrCRB"},"execution_count":null,"outputs":[]}]}